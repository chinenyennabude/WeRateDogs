{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle Report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data wrangling is the first and important step in any data analysis work, Data wrangling involves the process of cleaning and familarising oneself with the data inorder to get the data in a form that is useable.\n",
    "this step includes:\n",
    "\n",
    "1. Gathering Data\n",
    "This step involves collecting/selecting a dataset of choice and then I will load it into a dataframe using the pandas library.\n",
    "\n",
    "2. Assessing Data\n",
    "After loading the data in a pandas dataframe, we can now assess the data by checking its shape(i.e how many rows and columns), check for datatypes(i.e if the variable is a float, string, int or datatime), then we would also check for missing values as demonstrated in the cells below.\n",
    "\n",
    "3. Cleaning Data\n",
    "Real life data is dirty, inconsistent and incomplete, so we would need to clean the dataset if there are missing values by either deleting or replacing the values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gathering data:**\n",
    "Data for this project was gotten from three sources\n",
    "1.A file on hand(twitter_archive.csv) manually downloaded fron udacity link and read into a pandas dataframe for further assesment and analysis.\n",
    "2.The image_predictions.tsv dataset was downloaded programmatically from udacity's server.\n",
    "3. Additional retweet count and favorite count was obtained from Twitter's API using the tweepy library.\n",
    "\n",
    "**Assessing data**\n",
    "After obtaining datasetsfrom the 3 sources each of the dataset was assessed visually and programmatically for quality and tirediness issues\n",
    "\n",
    "**Cleaning**\n",
    "Eight quality/dirty issues which are content issues where observed from the dataset,these issues noted at the point of assessing the datasets were then cleaned so as to get the data a useable form.\n",
    "\n",
    "**Analysis**\n",
    "The data is further analysed to answer a problem question and gain insights from the data, this was done by carrying out data visualisations on the master dataset,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carrying out Data wrangling on the datasets has aided less noise and errors in analysing and interpreting the data and further prove how important this process is in any data analysis work.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
